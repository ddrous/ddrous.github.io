---
title: "A parallel theory of the causal mind"
author: "RD2N"
date: "2023-07-23"
categories: [Cognitive Science, Parallel Computing, Differential Equations]
format:
  html:
    toc: true
number-sections: true
filters:
  - social-share
share:
  permalink: "https://ddrous.github.io/posts/parallel-mind-theory/"
  description: "A complete theory about how the mind and body connect"
  twitter: true
  facebook: true
  reddit: true
  stumble: true
  tumblr: true
  linkedin: true
  email: true
  mastodon: true
comments:
  giscus:
    repo: ddrous/ddrous.github.io
---


```{=html}
<blockquote cite="https://youtu.be/zi7Va_4ekko"> How do we fit our conception of ourselves (the human reality) with what the world is at its most fundamental level: physical particles and fields of forces ? </blockquote
```


I've always been fascinated by theories of the mind and how to fully replicate it with artificial general intelligence. Lately, the philosophical nature of this problem is one that I've found myself pondering over a lot. Hoping not to get into too much detail, I'll talk about two technologies I believe are key to deciphering how the human mind works: Neural Ordinary Differential Equations, and Time-Parallel Computing. This article is based on ideas I collected from John Searle's course  [_Philosophy of Mind_](https://youtu.be/zi7Va_4ekko), and Malcolm Gladwell's best-selling book [_Blink_](https://www.audible.co.uk/pd/Blink-Audiobook/B004F2Z324).



## The mind-body problem


The mysteries of consciousness and the soul are some of the most challenging questions of our time. To tackle these questions, the Cartesian view postulates the existence of two realms: a real of __Mind__ (whose essence is the "thinking"), and a real of __Body__ (or the physical)[^1]. The mind is indivisible, undoubtable (hence the famous phrase "_I think, therefore I am._"), and commands the body. This fomulation, whose ideas we carry to this day, is an apt introduction to the dualist view, despite being a gross oversimplification of RenÃ© Descartes' legacy.

The dualist formulation dated back to the 17th century and is convenient for its time, as it leaves the realm of Body to __science__, and the realm of Mind to __religion__. Perfect if you're a scientist trying to conduct thought-provoking research under the Inquisition. Descartes's theory is appealing, but it leaves us with one big problem: how does the mind influence the brain? How are the two realms connected? Descartes's answer to this Mind-Body puzzle was unconvincing.

Over the centuries, several schools of thought have sought an answer to the puzzle, at times only considering one of the two realms. The main groups being __idealism__ and __behaviourism__ for Mind and Body, respectively. This is beautifully explained by John Searle in his course [Philosophy of Mind](https://youtu.be/zi7Va_4ekko). It would appear that the advent of computers and the emergence of the cross-disciplinary field of __cognitive science__ is the key to this puzzle.

{{< video https://youtu.be/zi7Va_4ekko 
    title='Philosophy of Mind - Lecture 1' 
>}}


## The bottom-up mind-body causality

Computers function by means of __algorithms__: carefully established instructions relating an input to an output. If one were to think of the brain (and *daringly* the mind too) as a computer, then the causal relation between the brain and the mind would have to be at the heart of such formalism. That is the essence of cognitive science.

When you feel pain, hunger or joy, there's no doubt these are neurobiological processes in your brain firing. This suggests that the mind reacts to the behaviour of the world; it is caused by brain processes. On the other hand, when you decide to raise your hand and it goes up, or when you go from being unhappy to being ecstatic, neuroscientists can clearly observe a change in the physical disposition of your brain. In other words, your mind is a state of your brain, a feature.

As explained by Searle, the brain **causes** the mind, and the mind is a **feature** of the brain. This would appear paradoxical, but no, it isn't. It makes sense if we think of the mind as made up of the higher-level processes compared to what we measure in the brain. For instance, when you decide to raise your hand and it goes up, there are two ways to interpret what happened: (1) neurons activated somewhere in your brain, sent a signal that travelled to your muscles, then causing your hand to go up (the _low-level_ processes); (2) you had a thought, and you observed the materialisation of it as a hand in the air (the _high-level_ process). Both interpretations are equally and simultaneously true.

__How do higher-level systemic features emerge from low-level individual characteristics__? This is the research question we've been after. We've turned an abstract philosophical puzzle into a very materialistic one; a scientific problem that includes the mind (unlike Descartes' original formulation). Mind-blowing behaviour emerging from simplistic elementary processes is widespread in nature. My favourite example is the swirl of Starling birds. 

{{< video https://youtu.be/V4f_1_r80RY 
    title='Flight of the Starlings' 
>}}

::: {.callout-note}
This idea isn't particularly groundbreaking. I've recently heard, on the [Joy of Why](https://www.quantamagazine.org/tag/the-joy-of-why/) podcast, about Professor Anil Seth and his pursuit of similar research questions at the University of Sussex.
:::


## A new model for the mind and the brain

As an applied mathematician, the propagation of brain signals and the elusive bottom-up causality between low- and high-level processes remind me of two specific tools: __differential equations__ and __neural networks__. I liken the causality and evolutionary nature of brain processes to ordinary differential equations (ODEs) as they describe individual dynamics. I then ascribe the compositionality of simple behaviour into larger features --- difficult to account for with our current understanding of neuroscience --- to deep neural networks.

As it turns out, those two concepts have been merged in what is now known as [Neural ODEs](https://proceedings.neurips.cc/paper_files/paper/2018/hash/69386f6bb1dfed68692a24c8686939b9-Abstract.html). Our model for the mind-body relation is formulated as follows
\begin{align}
\frac{\text{d} y}{\text{d} t}(t) &= f_{\theta}(y,t) \qquad t \in ]t_0, t_f [ \\
y(t_0) &= y_0 \\
z(t) &= g_{\theta'}(\theta, y, y_0, t, t_0, t_f),
\end{align}
where $y$ represents the physical signal transported and processed inside the brain. The transformative function $f_{\theta}$ --- where the learnable parameters $\theta$ indicate a deep neural network[^2] --- dictates how such continuous processing occurs. The mysterious **readout** function $g_{\theta'}$ tells us how a brain stimulus $y_0\in \mathbb{R}^b$ turns into a global mind feature $z \in \mathbb{R}^m$ (with $m\gg b$, i.e. potentially lots more elements involved in forming a mind compared to processing an elementary brain signal).

![Figure 1: Illustration of the Neural ODE model for the computational mind/brain relation](MindBodyProblem.png)



The Neural ODE paradigm has found breathtaking success, particularly as a drop-in replacement for [ResNets](https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html). But neural networks today can grow to extremely large sizes with billions of parameters in the weights $\theta$. They are energy and computationally inefficient compared to the human brain from which they are inspired. What if this network didn't have a fixed structure? What if neurons could dynamically adapt to the task at hand? These are the questions that [Liquid Neural Networks](https://ojs.aaai.org/index.php/AAAI/article/view/16936) attempt to answer. They were inspired by the efficiency of the worm's brain, made up of merely 300 neurons; and have shown jaw-dropping performance in autonomous driving. I believe Neural ODEs and Liquid Neural Networks could be combined within a __Liquid Neural ODE__ paradigm, thus unlocking the secrets of consciousness.



## Accounting for the subconscious

As a full-time daydreamer, I believe any theory of the mind must account for the subconscious; although not necessarily as envisioned by Sigmund Freud, since I don't believe his deeply abstract (and quite frightening) but brillant ideas are indispensable to replicating the human mind. That is why I think there's a __second computer__ at work in the back of our minds, even when we are awake. The same computer that quickly processes information and lets a car driver avoid pedestrians in an emergency situation. The kind of computer that shows us how we're all carrying [implicit biases](https://implicit.harvard.edu/implicit/takeatest.html). The same one we make use of on first impressions. The computer in the background that professionals use to identify talent without even knowing such things are happening subconsciously.

If those ideas sound familiar, that's because they are collected from Malcolm Gladwell's bestselling book [Blink](https://www.audible.co.uk/pd/Blink-Audiobook/B004F2Z324). Gladwell repeatedly uses the terminology __thin slicing__. He describes a computer that, given sufficient experience in a domain, discards all useless information to make the quickest decisions for our assumed benefit. The moral of the book is: _listen to your inner voice, but know when to ignore it_. Besides the discarding of useless information, I believe thin slicing happens so quickly because of the superior computational performance of that second computer. 

So, how can this idea complement the Neural ODE (which represents the conscious mind in our model)? Well, we parallelise it. The model above, given an heterogenous input vector $y$, should split the time-horizon $]t_0, t_f[$ and distribute the chunks to much smaller units of compute in order to return faster results at competitive accuracy. This can be achieved if two time domains are considered, one __coarse__ on which guesses for $y$ and $z$ are refined, and one __fine__ on which brain units work in parallel. We can interpret this parallelisation as signals coming from various senses at different times, and processed by different units within the brain. What I'm describing is combined data- and time-parallelisation. We train the Neural ODE on a fine time domain with a large $y$ containing all possible information, but under subconscious thin slicing conditions, we make sure inference happens on the coarse time domain with a smaller less informative $y$ in successive stages.

Several works have investigated parallel ideas on Neural ODEs, namely [Gunther et al.'s](https://epubs.siam.org/doi/abs/10.1137/19M1247620) and [Massaroli et al.'s](https://proceedings.neurips.cc/paper/2021/hash/89b9c689a57b82e59074c6ba09aa394d-Abstract.html). However, they only considered time (or layer) parallelism. Moreover, they focus on the training, and show very limited interest for inference. Combining data and time for quick but accurate inference is a dream I hope to achieve before then end of my PhD in September 2025.


## Closing toughts

I'm currently investigating the feasibility of a data-time parallel Neural ODE with applications to PDE simulation. How would we test such an idea on the brain? I have no clue yet. What I know is that I can start with my brain, like in the famous [Chinese Room](https://plato.stanford.edu/entries/chinese-room/) argument[^3] (as Searle says, "_always test the theory on yourself first_").

If your mind finds itself drawn to these ideas, then maybe they're valid. In that case, [send me a message](https://ddrous.github.io/about.html#contact-me). If you've heard these same ideas somewhere else and think I'm wasting my time or that there's room for collaboration, then please do reach out. If this sounds like complete nonsense to you, then maybe it is. It shouldn't stop us from pursuing the truth though, right ?

Using your [GitHub](https://github.com/) account, please comment below for any insights you might have. And as always, thanks for reading !

[^1]: This is the best I can do the define what the mind is, as opposed to what the body is. In this article, the body is reduced to the brain without loss of generality.
[^2]: In this model, $\theta$ is optional in cases where neurobiological input-output relations are fully understood. $\theta'$ on the other hand, is not optional.
[^3]: While it concedes the idea of a computational brain, this argument proves computation _alone_ cannot explain the mind. In our model, we account for that with our readout function $g_{\theta'}$.
