[
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Home\n    Publications\n  \n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n         \n          Publication\n        \n         \n          Year\n        \n     \n  \n    \n      \n      \n    \n\n\n  \n    Accelerating Algebraic Multigrid Using Machine Learning\n    **Nzoyem**, Louw, McIntosh-Smith & Deakin\n    HPC Reaserach Group - University of Bristol (PhD Summer Project)\n    (2022)\n    \n      Details\n    \n    \n       Preprint\n    \n  \n  \n    Fracturation de floes de glace par percussion dans un modèle granulaire\n    **Nzoyem**, Labbé & Prud'homme\n    Laboratoire Jacques-Louis Lions - Sorbonne Université (MSc Thesis)\n    (2021)\n    \n      Details\n    \n    \n       Preprint\n    \n  \n  \n    Simulation 2D de l’équation du transfert radiatif et reconstruction de la densité par un réseau de neurones\n    **Nzoyem**, Franck, Navoret, Vigon & Prud'homme\n    Institut de Recherche Mathématique Avancée (MSc Thesis)\n    (2020)\n    \n      Details\n    \n    \n       Preprint\n    \n  \n\n\nNo matching items"
  },
  {
    "objectID": "publications/theses/nzoyem2021fracturation.html",
    "href": "publications/theses/nzoyem2021fracturation.html",
    "title": "Fracturation de floes de glace par percussion dans un modèle granulaire",
    "section": "",
    "text": "Google Scholar"
  },
  {
    "objectID": "publications/theses/nzoyem2021fracturation.html#citation-apa",
    "href": "publications/theses/nzoyem2021fracturation.html#citation-apa",
    "title": "Fracturation de floes de glace par percussion dans un modèle granulaire",
    "section": "Citation (APA)",
    "text": "Citation (APA)\n\nNzoyem, R., Labbé, S. & Prud’homme, C. (2021). Fracturation de floes de glace par percussion dans un modèle granulaire."
  },
  {
    "objectID": "publications/theses/nzoyem2021fracturation.html#abstract",
    "href": "publications/theses/nzoyem2021fracturation.html#abstract",
    "title": "Fracturation de floes de glace par percussion dans un modèle granulaire",
    "section": "Abstract",
    "text": "Abstract\nThe rapid shrinking of the Arctic ice cap these last decades is seen as one of the most striking manifestations of global warming. This decrease in size opens way to new opportunities, namely the creation of routes beneficial to the industrial sector. The second major consequence of this observation that we need to include the Marginal Ice Zone (MIZ) into climate prediction models. In 2015, Rabatel et al.1 developed a sophisticated model for the dynamics of rigid ice floes. The model was later enhanced by Balasoiu in 2020 when he considered the ice floe not as rigid, but as an elastic material modeled by a mass‐spring‐damper lattice2. Our main goal in this report is to study what happens when two or more ice floes collide (percussion, fracture, etc.), both in 1D and in 2D."
  },
  {
    "objectID": "publications/theses/nzoyem2021fracturation.html#footnotes",
    "href": "publications/theses/nzoyem2021fracturation.html#footnotes",
    "title": "Fracturation de floes de glace par percussion dans un modèle granulaire",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMatthias RABATEL et al. « Dynamics of an assembly of rigid ice floes ». In : Journal of Geophysical Research : Oceans 120.9 (2015), p. 5887‐5909.↩︎\nDimitri BALASOIU. « Modélisation et simulation du comportement mécanique de floes de glace ». Theses. Université Grenoble Alpes [2020‐….], oct. 2020. URL : https://tel. archives-ouvertes.fr/tel-03116132.↩︎"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Home\n    Projects\n  \n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nAI4HPC\n\n\n\nAI\n\n\nHPC\n\n\nFluid Dynamics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArcticFloes\n\n\n\nModelling\n\n\nFunctional Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(Phi\\)-FEM\n\n\n\nModelling\n\n\nScientific Computing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVnetCancer\n\n\n\nAI\n\n\nSimulation\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/phifem/index.html",
    "href": "projects/phifem/index.html",
    "title": "\\(Phi\\)-FEM",
    "section": "",
    "text": "In recent years, numerical models using the Finite Elements Method (FEM) to simulate the soft tissue mechanisms of the human body have attracted a great interest. In the context of computer-assisted surgery, the simulation method should be quick, precise, and patient-specific. This work develops a new immersed boundary method named φ-FEM to address those issues.\nSoftware: - Fenics - SOFA"
  },
  {
    "objectID": "projects/arcticfloes/index.html",
    "href": "projects/arcticfloes/index.html",
    "title": "ArcticFloes",
    "section": "",
    "text": "The rapid shrinking of the Arctic ice cap these last decades is seen as one of the most striking manifestations of global warming. We investigated what happens when two or more ice floes collide, both in 1D and in 2D. We started by modelling an ice floe as a mass-spring-damper lattice, then we derived convergence guarantees with respect to its dynamics (percussion, fracture, etc.).\nSoftware stack: - Python Flask"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome to our brand new website",
    "section": "",
    "text": "This is my very first post in this blog. Welcome!\n\nI’ve never really owned a blog. Even though it’s been on my mind for more than 2 years now.\nNow that I’ve got a band new portfolio website, I feel like I’m never going to get a better opportunity than this to flesh out some of my ideas.\nThe previous iterations of my personal websites are not accessible anymore. But snapshoots can be found below.\n\nPhoto of Version 1: FOS version 1\nPhoto of Version 2: FOS version 2\n\nNothing was wrong with either of those versions. My only concern was that I couldn’t write code like in iPython notebooks. That feature is something I rely on a lot for my Data Science tutorials.\nThis version of the FOS (version 3) website is built on Quarto which fully support in-line code cells in Python and Julia, my main scripting languages. It offered template more gorgeos than anything that I could’ve found anywhere else.\nIt is a bit slower though.\nNow that you know my reasons for making these changes, you can tell me what you think. Which version of FOS looks the best accoring to you ?\nPOOL"
  },
  {
    "objectID": "posts/mesh-free-simulation/index.html",
    "href": "posts/mesh-free-simulation/index.html",
    "title": "Mesh-free simulation in the age of Big Data",
    "section": "",
    "text": "This is goign to be about why we need mesh-fre simulations:\n\nMeshes are heavy [AsiMov costs 3TB]\nComplex geometries can easily be point-clouded rather than meshesd\nMost data is represented as point clouds in computer graphics"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Home\n    CV\n  \n\n\n\n\n\n  \n     Download current CV"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Roussel",
    "section": "",
    "text": "Home\n    About\nHi there ! I’m a PhD student in HPC-AI at the University of Bristol, investigating parallel algorithms for combined data-driven and physics-informed simulation and control. I’m advised by Dr Tom Deakin, Pr David Barton, and Pr Simon McIntosh-Smith.\nMy research interests are at the intersection of Artificial Inteligence, Scientific Computing, and High Performance Computing. Some of the questions I ponder are:\nFor more details, read my CV or view my profile on LinkedIn. If they grab your attention, please do send me a message."
  },
  {
    "objectID": "about.html#cornerstones",
    "href": "about.html#cornerstones",
    "title": "Roussel",
    "section": "Cornerstones",
    "text": "Cornerstones\nA few quotes describe me better than any essay I could ever write:\n\nGod grant me the serenity to accept the things I cannot change, courage to change the things I can, and the wisdom to know the difference - The Serenity Prayer\nTime waits for no one - uttured in The Girl Who Leapt Through Time"
  },
  {
    "objectID": "about.html#hobbies",
    "href": "about.html#hobbies",
    "title": "Roussel",
    "section": "Hobbies",
    "text": "Hobbies\n\n\n\n\n\n\nI enjoy all things computer hardware, software and games: from old classics to AAA’s like DOOM. Nothing like a first-person shooter to evade your troubles.\n\n\n\n\n\n\n\nIn another life, I’m pretty sure I am/was a moviemaker.\n\n\n\n\n\n\n\n\n\nMy Casiotone CT-S100. I’ve just recently taken back to playing the piano. Hopefully some of my pieces will feature here soon.\n\n\n\n\n\n\n\nFootball is life. I play weekly in one of Bristol’s minor leagues. Call me if you’re putting together a game."
  },
  {
    "objectID": "about.html#address",
    "href": "about.html#address",
    "title": "Roussel",
    "section": "Address",
    "text": "Address"
  },
  {
    "objectID": "about.html#contact-me",
    "href": "about.html#contact-me",
    "title": "Roussel",
    "section": "Contact Me",
    "text": "Contact Me"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Roussel.",
    "section": "",
    "text": "This website is about my professional journey. You’ll also find interesting stories on various topics in hard and cognitive sciences, and some even more random stuff.\nTo learn more about me, go to the About page. In Projects and Publications, you’ll find some work I’ve contributed to, along with the tech stack I’ve mastered over the years. For some very random stuff, go to Blog where you’ll find a curated list of stories, articles, and poems. I hope you’ll enjoy !"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Roussel.",
    "section": "",
    "text": "This website is about my professional journey. You’ll also find interesting stories on various topics in hard and cognitive sciences, and some even more random stuff.\nTo learn more about me, go to the About page. In Projects and Publications, you’ll find some work I’ve contributed to, along with the tech stack I’ve mastered over the years. For some very random stuff, go to Blog where you’ll find a curated list of stories, articles, and poems. I hope you’ll enjoy !"
  },
  {
    "objectID": "index.html#news",
    "href": "index.html#news",
    "title": "Roussel.",
    "section": "News",
    "text": "News\n\n01 Aug. 2023 : I’ve pre-released version 0.1.4 of Updec: a mesh-free differentiable software for quick experimentation with a variety of PDEs. ☞ Repo.\n10 Mar. 2023 : I gave a talk at CMU Africa on emerging techniques and applications of graph neural networks. ☞ Recording.\n01 Dec. 2022 : I began my research on AI and HPC for mesh-free simulations. ☞ Synopsis.\n10 Oct. 2021 : I moved to Bristol for a PhD in the Interacrive AI CDT. Find pictures of my trips on ☞ Instagram."
  },
  {
    "objectID": "index.html#selected-stories",
    "href": "index.html#selected-stories",
    "title": "Roussel.",
    "section": "Selected stories*",
    "text": "Selected stories*\n\nA computational theory of the causal mind ➡️ Read\nWelcome to our brand new website ! ➡️ Read\nMesh-free simulation in the age of Big Data ➡️ Comming soon …\n\nStay up to date and get more stories by signing up for my weekly newsletter in the Blog section."
  },
  {
    "objectID": "index.html#selected-publications",
    "href": "index.html#selected-publications",
    "title": "Roussel.",
    "section": "Selected publications*",
    "text": "Selected publications*\n\nAccelerating Algebraic Multigrid Using Machine Learning ☞ Abstract\nFracturation de floes de glace par percussion dans un modèle granulaire ☞ Abstract\nSimulation 2D de l’équation du transfert radiatif et reconstruction de la densité par un réseau de neurones ☞ Abstract\n\nAll publications can be found in the Publications section.\n  Reach out"
  },
  {
    "objectID": "posts/parallel-mind-theory/index.html",
    "href": "posts/parallel-mind-theory/index.html",
    "title": "A parallel theory of the causal mind",
    "section": "",
    "text": "I’ve always been fascinated by the theory of the mind, and how to fully replicate it. But lately I’ve found the pholosiphical nature of the question more and more frustrating. The following article is based on ideas I collected from Malcolm Gladwell’s book Blink, and John Searle’s course on the Philosophy of Mind. Hoping not to get into too much detail, I’ll talk about a few technologies: Parallel Computing, and Neural Differential Equations."
  },
  {
    "objectID": "posts/parallel-mind-theory/index.html#the-mind-body-problem",
    "href": "posts/parallel-mind-theory/index.html#the-mind-body-problem",
    "title": "A parallel theory of the causal mind",
    "section": "1 The Mind-Body problem",
    "text": "1 The Mind-Body problem\nThe Cartesian theory postulates that there are two realms: a real of mind, and a real of body. The mind commands the body (which is only there for the ride). This is Rene Descarte’s legacy, whose remants we carry to this day.\nThis formulation dating back to the 1600s is convenient for it’s time, as it leaves the Realm of the Body to the science, and the Realm of the Mind to the church. Perfect if you’re a scientist wanting to conduct your research under the inquisitions.\nFinger pointing appart, this teory is appealing. But it leaves us with one big problem. How does the mind influence the brain ? How are the two realms connected ? Descarte’s answer to this puzzled was unconvinding.\nOver the centuries, several school of thoughts have emerged only considering one of the thoughts. The main groups being idealism and behaviourism. It would appear that the advent of computers and the emergence of the cross-disciplinary field of congnitive science is the key to this puzzle."
  },
  {
    "objectID": "posts/parallel-mind-theory/index.html#the-causal-brain",
    "href": "posts/parallel-mind-theory/index.html#the-causal-brain",
    "title": "A parallel theory of the causal mind",
    "section": "2 The causal brain",
    "text": "2 The causal brain\nWhen you feel good pain, hunger, or joy, there’s no doubt that these are neuro-biological processes in your brain firing. This suggest that the mint reacts to the behaviour of the world, it is caused by the brain processes.\nOn the other hand, when you go from being unhappy to being extatic, we can clearly see a change in the physical disposition of your brain. In other words, your mind is a state of your brain, a feature.\nAs explained by John Searle, the brain causes the mind, and the brain is a feature of the mind. This would appear paradoxal, but no. It makes sense if we think of the mind as made up of the higher-level processes than what we measure in the brain.\nDoesn’t this causality principle remind you of something(s) specific ? Differential equations and Neural Networks. Therefore, we liken the causality and evolutionary nature of the brain to ordinaty differential equations (ODE). Wereas we ascribe the compositionality of it to Deep Neural Networks.\nAs it turns out, those two concepts have been merged in what is now known as Neural ODEs, typically formulated as follows: \\[\\begin{align}\n\\frac{\\text{d} y}{\\text{d} t}(t) &= f_{\\theta}(y,t), \\qquad t \\in ]t_0, t_f [ \\\\\ny(t_0) &= y_0, \\\\\nz(t) &= g_{\\theta'}(\\theta, y, y_0, t, t_0, t_f),\n\\end{align}\\] where \\(y\\) represents the physical state in which the brain is in. The transformative function \\(f_{\\theta}\\) – where the learnable parameters \\(\\theta\\) indicte a Deep Neural Network – dictates how a physical signal is processed inside the brain. The misterious readout function \\(g_{\\theta'}\\) tells us how a brain signal \\(y_0\\in \\mathbb{R}^b\\) turns into a global mind feature \\(z \\in \\mathbb{R}^m\\) (with potentially lots more parameters).\n\n\n\nFigure 1: Illustration of the computational theory of the mind\n\n\nThat’s not all. Tipicall neural networks today can grow to extremely large size: billions of parameters in the weights \\(\\theta\\). What if this neural network doesn’t have a fixed structure? What if the neurons could dynamically adapt to the task at hand? This is the rapidly growing notions of Liquid Neural Networks inspired by the efficiency of the worm’s brain made up of mearly 300 neurons.\nThe Neural ODE paradigm has found breathtaking success, particularly againts ResNets [REF]. The Liquid Neural Network on the other hand has shown jaw-dropping perforamnce in autonomous driving [REF MIT]. I believe those two could be combined within the Liquid Neural ODE, unlocking the secrets of conciousness."
  },
  {
    "objectID": "posts/parallel-mind-theory/index.html#a-parallel-theory",
    "href": "posts/parallel-mind-theory/index.html#a-parallel-theory",
    "title": "A parallel theory of the causal mind",
    "section": "3 A parallel theory",
    "text": "3 A parallel theory\nAs a full-on daydreamer, I also believe any theory of the mind must account for the subconcious. Although not necessarily as decribed by Freud [REF] as I don’t believe those deeply abstract ideas are indispensable to replicating the human mind.\nThis is why I think there’s a second computer at work in the background of our minds, even when we are awake. The same computer that quickly processes information and let’s us avoid a car in an emergency situation. The kind of computer that shows us how we’re all carrying implict biases [REFs]. the same one we make use of on first impressions. The one professionals use to identify talent.\nIf those ideas sound familiar, that’s because the’re copied from Malcolm Gladwell’s betselling book Blink. He calls it thin slicing. A computer that, given sufficient experience in a domain, discards all unecassy information to make the quickest decisions critical for our survival. More often than none, the good one. The moral of the book is, listen to your inner voice, and know when to ignore it.\nSo how can this idea complement the Neural ODE (which represent our full mind in this analogy). Well, we parallelise it. The function \\(f\\), given a smaller input vector \\(y\\) and smaller weights \\(\\theta\\), should return faster results at competitive accuracy. What I’m describing is combined data- and time-parallastion. We solve the Neural ODE on a fine data-time domain, and we make sure it’s inference on a coarser data-time domain is just as accurate.\nSeveral works have investigated this idea on Neural ODE, namely Gunther [REF MULTIGRID IN TIME], Massaroli [REF DIFF LAYERS]. However, they only considered time (or layer) parallelism. Moreover, they focus on the training, rather than inference. Combinng at data and time for quick inference is a dream I hope to achieve before then end of my PhD (2025)."
  },
  {
    "objectID": "posts/parallel-mind-theory/index.html#closing-toughts",
    "href": "posts/parallel-mind-theory/index.html#closing-toughts",
    "title": "A parallel theory of the causal mind",
    "section": "4 Closing toughts",
    "text": "4 Closing toughts\nI’m currently investigating the feasablity of a data-time parallel Neural ODE in my PhD research. How would we test such an idea on the brain? I have no clue yet. All I know is that I can only start with my brain, as with the famous Chinese Room argument.\nIf your mind finds itself drawn to these ideas, then maybe they’re true (As Searle says, always test the theory on yourself first). In that case, send me a massage. If you’ve heard these same ideas somewhere else before and think I’m wasting my time, then please do send me a message. If this sounds like complete bullshit to you, that’s because maybe it is. It shouldn’t stop you from sending a kind message."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Home\n    Blog\n  \n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nMesh-free simulation in the age of Big Data\n\n\n\n\n\n\n\nsimulation\n\n\n\n\n\n\n\n\n\n\n\nJul 29, 2023\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nA parallel theory of the causal mind\n\n\n\n\n\n\n\nCognitive Science\n\n\nParallel Computing\n\n\nDifferential Equations\n\n\n\n\n\n\n\n\n\n\n\nJul 23, 2023\n\n\n6 min\n\n\n\n\n\n\n  \n\n\n\n\nWelcome to our brand new website\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJul 20, 2023\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/gnn4amg/index.html",
    "href": "projects/gnn4amg/index.html",
    "title": "AI4HPC",
    "section": "",
    "text": "How would you design a jet engine without ever buiding eanything ? This project introduces a Graph Neural Network model to acclerate the Algebraic Multigrid (AMG) method for linear systems. The goal is to improve AMG at its crucial prolongation step. The focus is on large and sparse linear systems coming from high-fidelity fluid simulation of gas-turbine engines during operation. This work mainly uses PyTorch, Deep Graph Library, and MATLAB.\nSoftware stack: - Deep Graph Library - Pytorch - JAX"
  },
  {
    "objectID": "projects/vnetcancer/index.html",
    "href": "projects/vnetcancer/index.html",
    "title": "VnetCancer",
    "section": "",
    "text": "We solved a computerized tomography inverse problem: given the signal on the boundaries of an organ, we want to rebuild the density map of the organ, hence detecting abnormally high density zones (which are potential indicators of early-onset cancer). Our main tasks were: simulating the radiative transfer equation; using Convolutional Neural Network to solve the related inverse problem; using a V-Net to improve accuracy and recreate the complete density map.\nSoftware stack: - Transfer - Eigen - Tensorflow\nRead an abstract of our report here."
  },
  {
    "objectID": "publications/theses/nzoyem2020simulation.html",
    "href": "publications/theses/nzoyem2020simulation.html",
    "title": "Simulation 2D de l’équation du transfert radiatif et reconstruction de la densité par un réseau de neurones",
    "section": "",
    "text": "Google Scholar"
  },
  {
    "objectID": "publications/theses/nzoyem2020simulation.html#citation-apa",
    "href": "publications/theses/nzoyem2020simulation.html#citation-apa",
    "title": "Simulation 2D de l’équation du transfert radiatif et reconstruction de la densité par un réseau de neurones",
    "section": "Citation (APA)",
    "text": "Citation (APA)\n\nNzoyem, R., Franck, E., Navoret, L., Vigon, V., & PRUD’HOMME, C. (2020). Simulation 2D de l’equation du transfert radiatif et reconstruction de la densité par un réseau de neurones."
  },
  {
    "objectID": "publications/theses/nzoyem2020simulation.html#abstract",
    "href": "publications/theses/nzoyem2020simulation.html#abstract",
    "title": "Simulation 2D de l’équation du transfert radiatif et reconstruction de la densité par un réseau de neurones",
    "section": "Abstract",
    "text": "Abstract\nEn 2015, le réseau de neurones vainqueur de l’ILSVRC1 obtient une précision de 97.3 % ce qui conduit les chercheurs à postuler que les machines peuvent identifier les objets dans des images mieux que les humains. Depuis lors, le domaine du Machine Learning a continué à prendre de l’ampleur. Aujourd’hui ses applications se multiplient dans plusieurs secteurs d’activité parmi lesquelles l’automobile, la finance, le divertissement, et plus important, celui de la santé à travers l’imagerie médicale.\nLes tumeurs ont des propriétés optiques différentes des tissus qui les entourent2. Étant donné un domaine avec un faisceau lumineux qui s’y propage, reconstruire sa densité à l’aide du signal temporel mesuré sur ses bords constitue un problème inverse. Les problèmes inverses sont très importants en sciences mathématiques et ont des applications variées en imagerie médicale, radar, vision, etc. Ils sont malheureusement très difficiles à résoudre car ils nécessitent l’utilisation d’algorithmes d’optimisation avancés. Les réseaux de neurones artificiels se présente comme une méthode potentiellement moins couteuse mais plus rapide.\nGrace à son unité mixte de recherche IRMA, l’UFR de mathématique et d’informatique de l’Université de Strasbourg est un pôle de recherche en mathématiques appliquées. À travers ses équipes MOCO et Probabilités, l’IRMA s’intéresse aux problématiques de modélisation des EDP et de Machine Learning, raison pour laquelle j’ai choisi d’y effectuer mon stage de master 1 CSMI3. Au cours de ce stage (du 15 juin au 15 août 2020), j’ai pu m’intéresser au problème inverse de reconstruction de la densité d’un domaine par un réseau de neurones convolutif (CNN).\nCe stage a été suivi par les enseignants-chercheurs MM. Emmanuel FRANCK, Laurent NAVORET, et Vincent VIGON et s’inscrit dans la continuation d’un projet (encadré par la même équipe) qui s’est déroulé du 19 mars au 28 mai 2020. Le projet consistait en la simulation 1D d’un schéma de « splitting » pour le modèle P1 de l’équation du transfert radiatif couplé avec la matière. Le stage quant à lui a essentiellement consisté en la simulation du même schéma en 2D, et en la reconstruction de la densité par un CNN. Plus généralement, ce stage a été l’opportunité pour moi d’apprendre sur les EDP et l’apprentissage profond tout en me familiarisant avec l’interface de programmation de la librairie de réseaux de neurones Keras.\nEn vue de rendre compte de manière fidèle des deux mois passés au sein de l’IRMA, il apparait logique de présenter en titre de préambule le cadre du stage et son environnement technique. Ensuite il s’agira de présenter les différentes missions et tâches qui j’ai pu effectuer. Enfin je présenterais un bilan du stage, en incluant les différents apports et enseignements que j’ai pu en tirer."
  },
  {
    "objectID": "publications/theses/nzoyem2020simulation.html#footnotes",
    "href": "publications/theses/nzoyem2020simulation.html#footnotes",
    "title": "Simulation 2D de l’équation du transfert radiatif et reconstruction de la densité par un réseau de neurones",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImageNet Large Scale Visual Recognition Challenge↩︎\nLes tissus cancéreux sont généralement plus denses que les tissus sains.↩︎\nCalcul Scientifique et Mathématiques de l’Information↩︎"
  },
  {
    "objectID": "publications/theses/nzoyem2022accelerating.html",
    "href": "publications/theses/nzoyem2022accelerating.html",
    "title": "Accelerating Algebraic Multigrid Using Machine Learning",
    "section": "",
    "text": "Google Scholar"
  },
  {
    "objectID": "publications/theses/nzoyem2022accelerating.html#citation-apa",
    "href": "publications/theses/nzoyem2022accelerating.html#citation-apa",
    "title": "Accelerating Algebraic Multigrid Using Machine Learning",
    "section": "Citation (APA)",
    "text": "Citation (APA)\n\nNzoyem, R., Louw, T., McIntosh-Smith, S. & Deakin, T., (2022). Accelerating Algebraic Multigrid Using Machine Learning: Application to problems originating from fluid simulation."
  },
  {
    "objectID": "publications/theses/nzoyem2022accelerating.html#abstract",
    "href": "publications/theses/nzoyem2022accelerating.html#abstract",
    "title": "Accelerating Algebraic Multigrid Using Machine Learning",
    "section": "Abstract",
    "text": "Abstract\nHigh-fidelity fluid simulations require solving extremely large and sparse linear systems, often in- volving millions of unknowns. With its fast convergence properties, Algebraic Multigrid (AMG) is the method of choice in several application areas. This said, classical AMG suffers from a number of issues, calling Machine Learning (ML) to the rescue. Recent years have seen a flourish of ML tactics to accelerate AMG. However, published work tends to focus on small and unrepresentative problems. Moreover, these methods tend to be developed dissociatively, not involving human end users in the process.\nWith insights from potential users, we aim to build a ML-augmented AMG framework that is: (i) robust i.e. reusable in a variety of problems arising from fluid simulation; (ii) computationally cheap i.e. converges faster than the classical AMG; (iii) works for structured as well as unstructured grids; (iv) works for small systems as well as large systems, while taking advantage of their sparsity; and (v) scalable i.e. data- and model-parallelisable with efficient memory management.\nThe main contributions of this project are as follows: (1) a Graph Neural Network methodology for learning prolongation operators, built around DGL and PyTorch; (2) a Cloud Formation stack on AWS to run experiments, containing all the dependencies our implementation requires; (3) ex- periments indicating that our current AI model is better than the classical approach in about 20% of cases; and (4) a survey that, among other remarks, endeared participants to using (AI-enabled) AMG for their various problems.\nOur work entails much efficient usage of HPC resources. By noticing that ML can be leveraged not only when solving linear systems, we pave the way for ML to be efficiently used in other parts of the high-fidelity simulation pipeline. Moreover, the consideration of users and their needs is a positive step towards broader Design Space Exploration of prolongation operators, model hyperparameters, and physical parameters influencing mechanical engines in operation."
  }
]